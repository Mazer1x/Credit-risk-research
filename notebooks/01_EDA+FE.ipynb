{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28cde236-8b30-47c5-828c-60b45c4b7cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import required libs\n",
    "\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21935293-8bd3-4ae9-8969-322a713c60ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = kagglehub.dataset_download(\"ranadeep/credit-risk-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a47ee7-b4f8-4409-9549-3a09153a9a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/12/17 17:22:35 WARN Utils: Your hostname, mazer1x-v15xv17xrnx, resolves to a loopback address: 127.0.1.1; using 192.168.0.107 instead (on interface wlp0s20f3)\n",
      "25/12/17 17:22:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/17 17:22:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# We have to use PySpark since our file weight is > 400 mb, so Pandas is not useful\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName('Spark')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b310dd1d-8292-41a8-a76c-c3e18d3a18a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mazer1x/miniconda3/envs/menv/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('../data/loan/loan.csv',header=True) # our main dataset\n",
    "columns_desc_pd = pd.read_excel('../data/LCDataDictionary.xlsx')\n",
    "columns_describe = spark.createDataFrame(columns_desc_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90be8fb0-0272-4eb6-8bf6-d2ec4d79c725",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97ee41b8-8be0-48f7-97e8-d33df9af5289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'string': 74}\n"
     ]
    }
   ],
   "source": [
    "# let's check column types\n",
    "columns = {}\n",
    "for _,t in df.dtypes:\n",
    "    if t not in columns: columns[t]=0\n",
    "    columns[t]+=1\n",
    "pprint(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de283243-f662-4c57-ac46-972af263b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % nans\n",
    "nan_percentage = df.select([\n",
    "    (F.round(\n",
    "        F.sum(\n",
    "            (F.col(c).isNull() | (F.col(c) == \"NaN\") | (F.col(c) == \"\")).cast(\"int\")\n",
    "        ) / df.count(),\n",
    "        2\n",
    "    )* 100).alias(c)\n",
    "    for c in df.columns\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00a2ba0c-bb13-4a85-aad4-e845c18e5d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/17 17:22:45 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "rows_dict = (nan_percentage.collect()[0]).asDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fab269c4-2a28-4b7b-9525-81f2ecd7e782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desc 52.0\n",
      "mths_since_last_delinq 57.99999999999999\n",
      "mths_since_last_record 89.0\n",
      "next_pymnt_d 66.0\n",
      "mths_since_last_major_derog 88.0\n",
      "annual_inc_joint 100.0\n",
      "dti_joint 100.0\n",
      "verification_status_joint 100.0\n",
      "tot_coll_amt 47.0\n",
      "tot_cur_bal 47.0\n",
      "open_acc_6m 100.0\n",
      "open_il_6m 100.0\n",
      "open_il_12m 100.0\n",
      "open_il_24m 100.0\n",
      "mths_since_rcnt_il 100.0\n",
      "total_bal_il 100.0\n",
      "il_util 100.0\n",
      "open_rv_12m 100.0\n",
      "open_rv_24m 100.0\n",
      "max_bal_bc 100.0\n",
      "all_util 100.0\n",
      "total_rev_hi_lim 47.0\n",
      "inq_fi 100.0\n",
      "total_cu_tl 100.0\n",
      "inq_last_12m 100.0\n"
     ]
    }
   ],
   "source": [
    "# Columns with 10%+ nans//nulls\n",
    "c = 0\n",
    "columns_to_drop = []\n",
    "for k,v in rows_dict.items(): \n",
    "    if v > 10: \n",
    "        c+=1\n",
    "        columns_to_drop.append(k)\n",
    "        print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bb2c962-fc14-4917-97b4-59a3f29c0365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 25\n"
     ]
    }
   ],
   "source": [
    "print(len(df.columns),c) # we can drop 25 cols. because of high nan %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b8ee30a-5e0e-4758-947a-7b855a938e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3187e730-7659-4d47-9fb5-f27e7b9c2fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e646df0d-4c5c-4230-bc74-bd0aa7442fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 91113\n",
      "member_id 91113\n",
      "loan_amnt 1095\n",
      "funded_amnt 1155\n",
      "funded_amnt_inv 9373\n",
      "term 2\n",
      "int_rate 448\n",
      "installment 25056\n",
      "grade 8\n",
      "sub_grade 36\n",
      "emp_title 53610\n",
      "emp_length 13\n",
      "home_ownership 6\n",
      "annual_inc 9282\n",
      "verification_status 4\n",
      "issue_d 60\n",
      "loan_status 10\n",
      "pymnt_plan 3\n",
      "url 91113\n",
      "purpose 268\n",
      "title 32200\n",
      "zip_code 1076\n",
      "addr_state 269\n",
      "dti 3697\n",
      "delinq_2yrs 228\n",
      "earliest_cr_line 758\n",
      "inq_last_6mths 219\n",
      "open_acc 144\n",
      "pub_rec 110\n",
      "revol_bal 34069\n",
      "revol_util 1257\n",
      "total_acc 226\n",
      "initial_list_status 157\n",
      "out_prncp 25128\n",
      "out_prncp_inv 25330\n",
      "total_pymnt 86617\n",
      "total_pymnt_inv 86075\n",
      "total_rec_prncp 37763\n",
      "total_rec_int 80117\n",
      "total_rec_late_fee 2915\n",
      "recoveries 6805\n",
      "collection_recovery_fee 5129\n",
      "last_pymnt_d 188\n",
      "last_pymnt_amnt 60930\n",
      "last_credit_pull_d 208\n",
      "collections_12_mths_ex_med 149\n",
      "policy_code 77\n",
      "application_type 55\n",
      "acc_now_delinq 41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91113"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(i,df.select(i).distinct().count())\n",
    "df.select(\"*\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe0f43eb-adcc-40ab-9582-56d17211d606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to drop, columns with (?) - extra check needed before drop.]\n",
    "#id, member_id, emp_title, url, title(?), zip_code, delinq_2yrs(?), inq_last_6mths(?), open_acc(?), \n",
    "#initial_list_status(?), issue_d,pymnt_plan\n",
    "\n",
    "# Post-issue\n",
    "#out_prncp, out_prncp_inv, total_pymnt, total_pymnt_inv,total_rec_prncp,total_rec_int,total_rec_late_fee\n",
    "#recoveries, collection_recovery_fee, last_pymnt_d, last_pymnt_amnt, collections_12_mths_ex_med,\n",
    "#last_credit_pull_d\n",
    "\n",
    "#first of all, lets drop post-issue columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "475c2bec-f84d-49b7-9a99-afce0ebdd890",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_issue_columns = ['out_prncp',\n",
    "    'out_prncp_inv',\n",
    "    'total_pymnt',\n",
    "    'total_pymnt_inv',\n",
    "    'total_rec_prncp',\n",
    "    'total_rec_int',\n",
    "    'total_rec_late_fee',\n",
    "    'recoveries',\n",
    "    'collection_recovery_fee',\n",
    "    'last_pymnt_d',\n",
    "    'last_pymnt_amnt',\n",
    "    'collections_12_mths_ex_med',\n",
    "    'last_credit_pull_d'\n",
    "] + [\n",
    "    'id',\n",
    "    'member_id',\n",
    "    'emp_title',\n",
    "    'url',\n",
    "    'zip_code',\n",
    "    'issue_d',\n",
    "    'pymnt_plan'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0202c9b7-c51b-40b8-94f4-7d17c3581804",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(*post_issue_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44185598-d3f4-41f3-ae98-58251ecea678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of \"problem\" columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "086ab060-8158-4241-b391-9998225b521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_cast = ['delinq_2yrs','inq_last_6mths','open_acc','initial_list_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "393e56ae-7f6c-4d2a-993d-1b7bd9d4d642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+--------+-------------------+\n",
      "|delinq_2yrs|inq_last_6mths|open_acc|initial_list_status|\n",
      "+-----------+--------------+--------+-------------------+\n",
      "|         31|            31|     111|              90904|\n",
      "+-----------+--------------+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in columns_to_cast:\n",
    "    df1 = df.withColumn(i, F.col(i).try_cast('double'))\n",
    "df1.select([\n",
    "    F.count(\n",
    "        F.when(\n",
    "            F.col(c).isNull(), 1)\n",
    "    ).alias(c)\n",
    "    for c in columns_to_cast\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b426c33e-3285-4ec5-8339-5366763b9768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, we can drop initial_list_status and remove columns with NULL-s: delinq_2yrs,inq_last_6mths,open_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1222461-23bb-4bfc-ab98-a2f968ae40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('initial_list_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00d69173-053a-42c3-b1a6-46d8432a1620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------\n",
      " loan_amnt           | 0   \n",
      " funded_amnt         | 0   \n",
      " funded_amnt_inv     | 0   \n",
      " term                | 0   \n",
      " int_rate            | 0   \n",
      " installment         | 0   \n",
      " grade               | 0   \n",
      " sub_grade           | 0   \n",
      " emp_length          | 0   \n",
      " home_ownership      | 0   \n",
      " annual_inc          | 0   \n",
      " verification_status | 0   \n",
      " loan_status         | 0   \n",
      " purpose             | 0   \n",
      " title               | 0   \n",
      " addr_state          | 0   \n",
      " dti                 | 0   \n",
      " delinq_2yrs         | 0   \n",
      " earliest_cr_line    | 0   \n",
      " inq_last_6mths      | 0   \n",
      " open_acc            | 0   \n",
      " pub_rec             | 0   \n",
      " revol_bal           | 0   \n",
      " revol_util          | 0   \n",
      " total_acc           | 0   \n",
      " policy_code         | 0   \n",
      " application_type    | 0   \n",
      " acc_now_delinq      | 0   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna() # data with NULL // NaN is less than 1% of the data\n",
    "df.select([\n",
    "    F.count(\n",
    "        F.when(\n",
    "            F.col(c).isNull(), 1)\n",
    "    ).alias(c)\n",
    "    for c in df.columns\n",
    "]).show(vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ed17d96-4fa3-42de-bb4d-b1cd705af963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to convert our data in needed types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cea2ba1f-132a-4518-92f9-c4af1b4bfd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------\n",
      " loan_amnt           | 5000.0      \n",
      " funded_amnt         | 5000.0      \n",
      " funded_amnt_inv     | 4975.0      \n",
      " term                |  36 months  \n",
      " int_rate            | 10.65       \n",
      " installment         | 162.87      \n",
      " grade               | B           \n",
      " sub_grade           | B2          \n",
      " emp_length          | 10+ years   \n",
      " home_ownership      | RENT        \n",
      " annual_inc          | 24000.0     \n",
      " verification_status | Verified    \n",
      " loan_status         | Fully Paid  \n",
      " purpose             | credit_card \n",
      " title               | Computer    \n",
      " addr_state          | AZ          \n",
      " dti                 | 27.65       \n",
      " delinq_2yrs         | 0.0         \n",
      " earliest_cr_line    | Jan-1985    \n",
      " inq_last_6mths      | 1.0         \n",
      " open_acc            | 3.0         \n",
      " pub_rec             | 0.0         \n",
      " revol_bal           | 13648.0     \n",
      " revol_util          | 83.7        \n",
      " total_acc           | 9.0         \n",
      " policy_code         | 1.0         \n",
      " application_type    | INDIVIDUAL  \n",
      " acc_now_delinq      | 0.0         \n",
      "only showing top 1 row\n"
     ]
    }
   ],
   "source": [
    "df.show(1,vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b1843c8-b5ba-43a5-a823-7daa183c7254",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_cols = ['loan_amnt','funded_amnt','funded_amnt_inv','int_rate','installment','annual_inc','dti','delinq_2yrs',\n",
    "           'inq_last_6mths','open_acc','pub_rec','revol_bal','revol_util','total_acc','policy_code','acc_now_delinq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56448337-dcef-4d17-9e0b-5922c6bcf313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------\n",
      " loan_amnt       | 0   \n",
      " funded_amnt     | 0   \n",
      " funded_amnt_inv | 0   \n",
      " int_rate        | 0   \n",
      " installment     | 0   \n",
      " annual_inc      | 0   \n",
      " dti             | 54  \n",
      " delinq_2yrs     | 54  \n",
      " inq_last_6mths  | 54  \n",
      " open_acc        | 52  \n",
      " pub_rec         | 43  \n",
      " revol_bal       | 30  \n",
      " revol_util      | 41  \n",
      " total_acc       | 36  \n",
      " policy_code     | 7   \n",
      " acc_now_delinq  | 20  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in double_cols:\n",
    "    df = df.withColumn(i, F.col(i).try_cast('double'))\n",
    "df.select([\n",
    "    F.count(\n",
    "        F.when(\n",
    "            F.col(c).isNull(), 1)\n",
    "    ).alias(c)\n",
    "    for c in double_cols\n",
    "]).show(vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33534410-b155-4317-a2dc-585a65bfb5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna() # to drop nan-s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4ff0c9-4c4e-4976-9a8c-acdda0add7ca",
   "metadata": {},
   "source": [
    "## Feature Engineering (FE) / String type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "852c9b4d-fd7e-47c1-af74-7f479285610b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loan_amnt', 'double'),\n",
       " ('funded_amnt', 'double'),\n",
       " ('funded_amnt_inv', 'double'),\n",
       " ('term', 'string'),\n",
       " ('int_rate', 'double'),\n",
       " ('installment', 'double'),\n",
       " ('grade', 'string'),\n",
       " ('sub_grade', 'string'),\n",
       " ('emp_length', 'string'),\n",
       " ('home_ownership', 'string'),\n",
       " ('annual_inc', 'double'),\n",
       " ('verification_status', 'string'),\n",
       " ('loan_status', 'string'),\n",
       " ('purpose', 'string'),\n",
       " ('title', 'string'),\n",
       " ('addr_state', 'string'),\n",
       " ('dti', 'double'),\n",
       " ('delinq_2yrs', 'double'),\n",
       " ('earliest_cr_line', 'string'),\n",
       " ('inq_last_6mths', 'double'),\n",
       " ('open_acc', 'double'),\n",
       " ('pub_rec', 'double'),\n",
       " ('revol_bal', 'double'),\n",
       " ('revol_util', 'double'),\n",
       " ('total_acc', 'double'),\n",
       " ('policy_code', 'double'),\n",
       " ('application_type', 'string'),\n",
       " ('acc_now_delinq', 'double')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23e8bafc-8c00-4262-9813-4a354597b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_cols = []\n",
    "for i in df.dtypes:\n",
    "    if i[1] == 'string': str_cols+=[i[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5be0cc57-e9a1-4821-b4e8-0fbb172c15fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------\n",
      " term                |  36 months  \n",
      " grade               | B           \n",
      " sub_grade           | B2          \n",
      " emp_length          | 10+ years   \n",
      " home_ownership      | RENT        \n",
      " verification_status | Verified    \n",
      " loan_status         | Fully Paid  \n",
      " purpose             | credit_card \n",
      " title               | Computer    \n",
      " addr_state          | AZ          \n",
      " earliest_cr_line    | Jan-1985    \n",
      " application_type    | INDIVIDUAL  \n",
      "only showing top 1 row\n"
     ]
    }
   ],
   "source": [
    "df.select(*str_cols).show(1,vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cabe526a-d5e9-42f7-b2a5-0953330a4277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should use GBT to solve our case, so we need to adapt our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98fe5603-92f0-4054-b214-d8053cbb7bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emp_length  - ordinal encoding\n",
    "# term - ordinal encoding encoding\n",
    "# grade + sub_grade - ordinal (check the cell below)\n",
    "# home_ownership - OHE\n",
    "# verification_status - ordinal encoding\n",
    "# purpose - OHE\n",
    "# title - Drop (31941 unique values)\n",
    "# addr_state - Transform to (West/East/...) -> OHE\n",
    "# earliest_cr_line - Int (From datetime to yeas in int format)\n",
    "# application_type - INDIVIDUAL, only 1 distinct val, drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e41cc2a-4ba9-4827-bc21-ac1faa7589fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can drop grade and use sub_grade instead. E5 = 1, E4 = 2, ..., A1 = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89267add-54af-446c-8570-78a3d4410143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.select('loan_status').distinct().show()\n",
    "#We can use Binary class. to exclude data leakage (instead of ternary —Ålassification)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
